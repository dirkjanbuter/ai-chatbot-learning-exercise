# Steps done so far and work in progress

• Corpus - Make a spider bot to crawl articles;
• Corpus - Make a language detector to filter non-English texts;
• Corpus - Detect the headers and paragraphs ('h1', 'h2', 'h3', ... 'p' tags) and filter script and style content ('script', 'style' tags);
• Corpus - Get hyperlinks ('a' tags) and save in a list to crawl later;
• Tokenization - Break the sentences of the paragraphs into sentence tokens;
• Tokenization - Break the sentence into word tokens, alpha and special characters separated by spaces and punctuation.
• Lexicon - Detect punctuation;
• Lexicon - Detect stop words;
• Lexicon - Detect numbers and written numbers in alphabets;
• Lexicon - Detect time and months, names, brands, colors, continent, countries, cities, etc.;
• Lexicon - Detect the word type by using a dictionary word list per word type;
• Stemming & Lemmatization - Convert nouns, verbs, adverb, etc.  forms into one usable form.
• Lexicon - convert paragraphs, sentences, words, word type to numbers based on their index number;
• Sentiment - Work in progress - The task of determining the overall attitude or emotion expressed in a text document;
• Language model - Work in progress - A probabilistic model that predicts the likelihood of a sequence of words or sentences;
      
